{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "test_file = open('test_dataset.pickle', 'rb')\n",
    "test_data = pk.load(test_file)\n",
    "\n",
    "train_file = open('train_dataset.pickle', 'rb')\n",
    "train_data = pk.load(train_file)\n",
    "\n",
    "train_data = np.random.permutation(train_data)\n",
    "train_sets = np.split(train_data, 20)\n",
    "\n",
    "tx = test_data[:,0].reshape((-1, 1))\n",
    "ty = test_data[:,1]\n",
    "\n",
    "mse = [0]*15\n",
    "bias = [0]*15\n",
    "error = [0]*15\n",
    "degree = [0]*15\n",
    "variance = [0]*15\n",
    "            \n",
    "for d in range(1, 16):\n",
    "    degree[d-1] = d\n",
    "    predicted = []\n",
    "    for s in range(0, 20):\n",
    "        x = train_sets[s][:,0].reshape((-1, 1))\n",
    "        x_ = PolynomialFeatures(degree=d, include_bias=False).fit_transform(x)\n",
    "        y = train_sets[s][:,1]\n",
    "\n",
    "        model = LinearRegression().fit(x_, y)\n",
    "        tx_ = PolynomialFeatures(degree=d, include_bias=False).fit_transform(tx)\n",
    "        y_pred = model.predict(tx_)\n",
    "        predicted.append(y_pred)\n",
    "        \n",
    "    for p in range(0, 200):\n",
    "        by = sum([item[p] for item in predicted]) / 20\n",
    "        vy = sum(map(lambda i: i*i, [item[p] for item in predicted])) / 20\n",
    "        bias_p = abs(by - ty[p])\n",
    "        var_p = vy - by**2\n",
    "        mse_p = ty[p]**2 + vy - 2*ty[p]*by\n",
    "        bias[d-1] += bias_p\n",
    "        variance[d-1] += var_p\n",
    "        mse[d-1] += mse_p\n",
    "        error[d-1] += mse_p - bias_p**2 - var_p\n",
    "    mse[d-1] /= 200\n",
    "    bias[d-1] /= 200\n",
    "    error[d-1] /=  200\n",
    "    variance[d-1] /= 200\n",
    "    \n",
    "plt.xlabel(\"Degree of Polynomial\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.plot(degree[:10], [i**2 for i in bias[:10]], 'b', label = \"Bias^2\")\n",
    "plt.plot(degree[:10], variance[:10], 'r', label = \"Variance\")\n",
    "plt.plot(degree[:10], mse[:10], 'g', label = \"MSE\")\n",
    "plt.show()\n",
    "\n",
    "error = np.array(error).reshape((-1, 1))\n",
    "print(tabulate(list(zip(degree, bias, variance, error)), headers=['degree', 'Bias', 'Variance', 'Irreducible Error'], tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
